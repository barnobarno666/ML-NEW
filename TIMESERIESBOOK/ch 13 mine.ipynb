{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 14:05:07.459040: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-20 14:05:07.460969: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-20 14:05:07.486422: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-20 14:05:07.486451: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-20 14:05:07.487219: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-20 14:05:07.491523: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-20 14:05:07.491988: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 14:05:08.132669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Lambda, Reshape, RNN, LSTMCell\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataWindow():\n",
    "    def __init__(self, input_width, label_width, shift, \n",
    "                 train_df, val_df, test_df, \n",
    "                 label_columns=None):\n",
    "        \n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        \n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
    "        \n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "        \n",
    "        self.total_window_size = input_width + shift\n",
    "        \n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "        \n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "    \n",
    "    def split_to_inputs_labels(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:,:,self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1\n",
    ")\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "        \n",
    "        return inputs, labels\n",
    "    \n",
    "    def plot(self, model=None, plot_col='traffic_volume', max_subplots=3):\n",
    "        inputs, labels = self.sample_batch\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "        \n",
    "        for n in range(max_n):\n",
    "            plt.subplot(3, 1, n+1)\n",
    "            plt.ylabel(f'{plot_col} [scaled]')\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                     label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "                \n",
    "              label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "              label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "              continue\n",
    "\n",
    "            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                        edgecolors='k', marker='s', label='Labels', c='green', s=64)\n",
    "            if model is not None:\n",
    "              predictions = model(inputs)\n",
    "              plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                          marker='X', edgecolors='k', label='Predictions',\n",
    "                          c='red', s=64)\n",
    "\n",
    "            if n == 0:\n",
    "              plt.legend()\n",
    "\n",
    "        plt.xlabel('Time (h)')\n",
    "        \n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=True,\n",
    "            batch_size=32\n",
    "        )\n",
    "        \n",
    "        ds = ds.map(self.split_to_inputs_labels)\n",
    "        return ds\n",
    "    \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "    \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "    \n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "    \n",
    "    @property\n",
    "    def sample_batch(self):\n",
    "        result = getattr(self, '_sample_batch', None)\n",
    "        if result is None:\n",
    "            result = next(iter(self.train))\n",
    "            self._sample_batch = result\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df =pd.read_csv(r'/media/barnobarno666/CODING/ALL CODES/ML NEW/TIMESERIESBOOK/ch 122/train.csv')\n",
    "test_df =pd.read_csv(r'/media/barnobarno666/CODING/ALL CODES/ML NEW/TIMESERIESBOOK/ch 122/test.csv')\n",
    "val_df =pd.read_csv(r'/media/barnobarno666/CODING/ALL CODES/ML NEW/TIMESERIESBOOK/ch 122/vali.csv')\n",
    "\n",
    "single_step_window = DataWindow(train_df=train_df,test_df=test_df,val_df=val_df,input_width=1, label_width=1, shift=1, label_columns=['traffic_volume'])\n",
    "wide_window = DataWindow(train_df=train_df,test_df=test_df,val_df=val_df,input_width=24, label_width=24, shift=1, label_columns=['traffic_volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(Model):\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        \n",
    "        elif isinstance(self.label_index, list):\n",
    "            tensors = []\n",
    "            for index in self.label_index:\n",
    "                result = inputs[:, :, index]\n",
    "                result = result[:, :, tf.newaxis]\n",
    "                tensors.append(result)\n",
    "            return tf.concat(tensors, axis=-1)\n",
    "        \n",
    "        result = inputs[:, :, self.label_index]\n",
    "        return result[:,:,tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'traffic_volume'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/media/barnobarno666/CODING/ALL CODES/ML NEW/TIMESERIESBOOK/ch 13 mine.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/barnobarno666/CODING/ALL%20CODES/ML%20NEW/TIMESERIESBOOK/ch%2013%20mine.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m column_indices \u001b[39m=\u001b[39m {name: i \u001b[39mfor\u001b[39;00m i, name \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_df\u001b[39m.\u001b[39mcolumns)}\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/barnobarno666/CODING/ALL%20CODES/ML%20NEW/TIMESERIESBOOK/ch%2013%20mine.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m baseline_last \u001b[39m=\u001b[39m Baseline(label_index\u001b[39m=\u001b[39mcolumn_indices[\u001b[39m'\u001b[39;49m\u001b[39mtraffic_volume\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/barnobarno666/CODING/ALL%20CODES/ML%20NEW/TIMESERIESBOOK/ch%2013%20mine.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m baseline_last\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mMeanSquaredError(), metrics\u001b[39m=\u001b[39m[MeanAbsoluteError()])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'traffic_volume'"
     ]
    }
   ],
   "source": [
    "column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
    "\n",
    "baseline_last = Baseline(label_index=column_indices['traffic_volume'])\n",
    "\n",
    "baseline_last.compile(loss=MeanSquaredError(), metrics=[MeanAbsoluteError()])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
