{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables and their dimensions:\n",
      "longitude: ('longitude',)\n",
      "latitude: ('latitude',)\n",
      "time: ('time',)\n",
      "tcc: ('time', 'latitude', 'longitude')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     data_dict[var_name] \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mvariables[var_name][:]\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Convert to pandas DataFrame\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Write to CSV file\u001b[39;00m\n\u001b[0;32m     27\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(csv_file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    705\u001b[0m     )\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:655\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    653\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    660\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the path to the NetCDF file\n",
    "netcdf_file_path = 'adaptor.mars.internal-1718528288.9433048-12824-8-9bdef7c5-a6f3-4d5e-a460-3dbfa7374948.nc'\n",
    "# Output CSV file path\n",
    "csv_file_path = 'output_1.csv'\n",
    "\n",
    "# Open the NetCDF file\n",
    "dataset = nc.Dataset(netcdf_file_path)\n",
    "\n",
    "# Display the variables and their dimensions\n",
    "print(\"Variables and their dimensions:\")\n",
    "for var_name in dataset.variables.keys():\n",
    "    var = dataset.variables[var_name]\n",
    "    print(f\"{var_name}: {var.dimensions}\")\n",
    "\n",
    "# Extract the variables and their data\n",
    "data_dict = {}\n",
    "for var_name in dataset.variables.keys():\n",
    "    data_dict[var_name] = dataset.variables[var_name][:].flatten()\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Write to CSV file\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"NetCDF file has been converted to CSV and saved at {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables and their dimensions:\n",
      "longitude: ('longitude',), shape: (5,)\n",
      "latitude: ('latitude',), shape: (5,)\n",
      "time: ('time',), shape: (696,)\n",
      "tcc: ('time', 'latitude', 'longitude'), shape: (696, 5, 5)\n",
      "NetCDF file has been converted to CSV and saved at output_5.csv\n"
     ]
    }
   ],
   "source": [
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the path to the NetCDF file\n",
    "netcdf_file_path = 'adaptor.mars.internal-1718528288.9433048-12824-8-9bdef7c5-a6f3-4d5e-a460-3dbfa7374948.nc'\n",
    "# Output CSV file path\n",
    "csv_file_path = 'output_5.csv'\n",
    "\n",
    "# Open the NetCDF file\n",
    "dataset = nc.Dataset(netcdf_file_path,mode='r')\n",
    "\n",
    "# Display the variables and their dimensions\n",
    "print(\"Variables and their dimensions:\")\n",
    "for var_name in dataset.variables.keys():\n",
    "    var = dataset.variables[var_name]\n",
    "    print(f\"{var_name}: {var.dimensions}, shape: {var.shape}\")\n",
    "\n",
    "# Prepare data for DataFrame\n",
    "data_dict = {}\n",
    "\n",
    "# Handle variables with different dimensions\n",
    "for var_name in dataset.variables.keys():\n",
    "    var_data = dataset.variables[var_name][:]\n",
    "    # Flatten the variable data\n",
    "    flattened_data = var_data.flatten()\n",
    "    data_dict[var_name] = flattened_data\n",
    "\n",
    "# Find the maximum length of the flattened data arrays\n",
    "max_length = max(len(data) for data in data_dict.values())\n",
    "\n",
    "# Ensure all arrays are of the same length by padding with NaNs\n",
    "for var_name, data in data_dict.items():\n",
    "    if len(data) < max_length:\n",
    "        data_dict[var_name] = pd.Series(data).reindex(range(max_length), fill_value=float('nan'))\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Write to CSV file\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"NetCDF file has been converted to CSV and saved at {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to the NetCDF file\n",
    "netcdf_file_path = '/mnt/data/adaptor.mars.internal-1718528288.9433048-12824-8-9bdef7c5-a6f3-4d5e-a460-3dbfa7374948.nc'\n",
    "# Output CSV file path\n",
    "csv_file_path = '/mnt/data/output.csv'\n",
    "\n",
    "# Open the NetCDF file\n",
    "dataset = nc.Dataset(netcdf_file_path)\n",
    "\n",
    "# Display the variables and their dimensions\n",
    "print(\"Variables and their dimensions:\")\n",
    "for var_name in dataset.variables.keys():\n",
    "    var = dataset.variables[var_name]\n",
    "    print(f\"{var_name}: {var.dimensions}, shape: {var.shape}\")\n",
    "\n",
    "# Prepare data for DataFrame\n",
    "data_dict = {}\n",
    "\n",
    "# Identify the main dimension (assuming the first dimension is the primary one)\n",
    "main_dim = list(dataset.dimensions.keys())[0]\n",
    "main_dim_size = len(dataset.dimensions[main_dim])\n",
    "\n",
    "# Extract the variables and their data, ensuring they are aligned by the main dimension\n",
    "for var_name in dataset.variables.keys():\n",
    "    var_data = dataset.variables[var_name][:]\n",
    "    \n",
    "    # Handle multi-dimensional arrays\n",
    "    if len(var_data.shape) > 1:\n",
    "        # Flatten the array but keep it aligned by the main dimension\n",
    "        var_data = var_data.reshape(main_dim_size, -1)\n",
    "    \n",
    "    data_dict[var_name] = var_data.flatten()\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame\n",
    "# This ensures that we handle repeated elements correctly by treating each row as an observation\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"NetCDF file has been converted to CSV and saved at {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xarray\n",
      "  Obtaining dependency information for xarray from https://files.pythonhosted.org/packages/ce/78/7a78d5197e409371c4fd9734ad9ab41ed6f9147b3ac23256c4e6c81295f2/xarray-2024.6.0-py3-none-any.whl.metadata\n",
      "  Downloading xarray-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\defaultuser0.laptop-lrb3t941\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from xarray) (1.23.5)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\defaultuser0.laptop-lrb3t941\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from xarray) (23.1)\n",
      "Requirement already satisfied: pandas>=2.0 in c:\\users\\defaultuser0.laptop-lrb3t941\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from xarray) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\defaultuser0.laptop-lrb3t941\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=2.0->xarray) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\defaultuser0.laptop-lrb3t941\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=2.0->xarray) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\defaultuser0.laptop-lrb3t941\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=2.0->xarray) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\defaultuser0.laptop-lrb3t941\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0->xarray) (1.16.0)\n",
      "Downloading xarray-2024.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.2 MB 330.3 kB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.1/1.2 MB 469.7 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.1/1.2 MB 654.9 kB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.2/1.2 MB 888.4 kB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.3/1.2 MB 962.4 kB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.3/1.2 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.5/1.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.6/1.2 MB 913.7 kB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.6/1.2 MB 913.7 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.9/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.9/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: xarray\n",
      "Successfully installed xarray-2024.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\defaultuser0.LAPTOP-LRB3T941\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241m.\u001b[39mopen_dataset(netcdf_file_in)\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mto_dataframe()\n\u001b[0;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(csv_file_out)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xr' is not defined"
     ]
    }
   ],
   "source": [
    "ds = xr.open_dataset(netcdf_file_in)\n",
    "df = ds.to_dataframe()\n",
    "\n",
    "df.to_csv(csv_file_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import pandas as pd\n",
    "\n",
    "precip_nc_file = 'file_path'\n",
    "nc = netCDF4.Dataset(precip_nc_file, mode='r')\n",
    "\n",
    "nc.variables.keys()\n",
    "\n",
    "lat = nc.variables['lat'][:]\n",
    "lon = nc.variables['lon'][:]\n",
    "time_var = nc.variables['time']\n",
    "dtime = netCDF4.num2date(time_var[:],time_var.units)\n",
    "precip = nc.variables['precip'][:]\n",
    "\n",
    "# a pandas.Series designed for time series of a 2D lat,lon grid\n",
    "precip_ts = pd.Series(precip, index=dtime) \n",
    "\n",
    "precip_ts.to_csv('precip.csv',index=True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "BlockingIOError",
     "evalue": "[Errno 11] Resource temporarily unavailable: '/mnt/data/adaptor.mars.internal-1718528288.9433048-12824-8-9bdef7c5-a6f3-4d5e-a460-3dbfa7374948.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBlockingIOError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/data/output.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Open the NetCDF file\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mnc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetcdf_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m dataset\n",
      "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:2470\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:2107\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mBlockingIOError\u001b[0m: [Errno 11] Resource temporarily unavailable: '/mnt/data/adaptor.mars.internal-1718528288.9433048-12824-8-9bdef7c5-a6f3-4d5e-a460-3dbfa7374948.nc'"
     ]
    }
   ],
   "source": [
    "import netCDF4\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to the NetCDF file\n",
    "netcdf_file_path = '/mnt/data/adaptor.mars.internal-1718528288.9433048-12824-8-9bdef7c5-a6f3-4d5e-a460-3dbfa7374948.nc'\n",
    "# Output CSV file path\n",
    "csv_file_path = '/mnt/data/output.csv'\n",
    "\n",
    "# Open the NetCDF file\n",
    "dataset = nc.Dataset(netcdf_file_path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variables and their dimensions:\n",
    "longitude: ('longitude',), shape: (5,)\n",
    "latitude: ('latitude',), shape: (5,)\n",
    "time: ('time',), shape: (696,)\n",
    "tcc: ('time', 'latitude', 'longitude'), shape: (696, 5, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "NetCDF: Attribute not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Open the NetCDF file\u001b[39;00m\n\u001b[0;32m     10\u001b[0m dataset \u001b[38;5;241m=\u001b[39m nc\u001b[38;5;241m.\u001b[39mDataset(netcdf_file_path)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariabls\u001b[49m\n",
      "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:3131\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__getattr__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:3076\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.getncattr\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:1617\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._get_att\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:2113\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: NetCDF: Attribute not found"
     ]
    }
   ],
   "source": [
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the path to the NetCDF file\n",
    "netcdf_file_path = 'adaptor.mars.internal-1718528288.9433048-12824-8-9bdef7c5-a6f3-4d5e-a460-3dbfa7374948.nc'\n",
    "# Output CSV file path\n",
    "csv_file_path = 'output_3.csv'\n",
    "\n",
    "# Open the NetCDF file\n",
    "dataset = nc.Dataset(netcdf_file_path)\n",
    "dataset.variabls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
